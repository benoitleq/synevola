# ü©∫ Synevola

**Transcription & R√©sum√© aid√© par IA en local**

Synevola est une application de transcription audio m√©dicale avec diarisation (identification des locuteurs) et g√©n√©ration automatique de r√©sum√©s, le tout fonctionnant **100% en local** pour garantir la confidentialit√© des donn√©es patients.

![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)
![Streamlit](https://img.shields.io/badge/Streamlit-1.33+-red.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)
![CUDA](https://img.shields.io/badge/CUDA-Optional-orange.svg)

---

## ‚ú® Fonctionnalit√©s

### üé§ Transcription Audio
- **Multi-format** : MP3, WAV, OGG, FLAC, M4A, WebM
- **Mod√®les Whisper** : tiny, base, small, medium, large, faster-whisper
- **Diarisation** : Identification automatique des locuteurs (pyannote.audio)
- **Renommage** : Possibilit√© de renommer les locuteurs (SPEAKER_00 ‚Üí Dr. Martin)

### üéôÔ∏è Enregistrement Audio
- **S√©lection du microphone** : Choix parmi les p√©riph√©riques disponibles
- **Contr√¥le du gain** : Ajustement du niveau d'entr√©e (0-200%)
- **VU-m√®tre temps r√©el** : Visualisation du niveau audio
- **Pause/Reprise** : Contr√¥le complet de l'enregistrement

### üß† R√©sum√© Intelligent
- **LLM local** : Int√©gration avec LM Studio (Mistral, Qwen, Llama, etc.)
- **Personnalisable** : Prompts syst√®me et utilisateur modifiables
- **Chunking intelligent** : Gestion des longs documents par blocs
- **Multi-modes** : R√©sum√© direct ou par blocs + synth√®se

### üì§ Export
- **TXT** : Transcription et r√©sum√© en texte brut
- **DOCX** : Compte rendu m√©dical format√© (Word)

---

## üöÄ Installation

### Pr√©requis

- Python 3.9 ou sup√©rieur
- [LM Studio](https://lmstudio.ai/) pour les r√©sum√©s IA
- ffmpeg pour le traitement audio
- (Optionnel) GPU NVIDIA avec CUDA pour acc√©l√©ration

### 1. Cloner le repository

```bash
git clone https://github.com/votre-username/synevola.git
cd synevola
```

### 2. Cr√©er un environnement virtuel

```bash
python -m venv .venv

# Windows
.venv\Scripts\activate

# macOS/Linux
source .venv/bin/activate
```

### 3. Installer les d√©pendances

```bash
pip install -r requirements.txt
```

### 4. Installer ffmpeg

```bash
# Windows (avec Chocolatey)
choco install ffmpeg

# macOS (avec Homebrew)
brew install ffmpeg

# Linux (Ubuntu/Debian)
sudo apt install ffmpeg
```

### 5. (Optionnel) Support GPU CUDA

```bash
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

### 6. Token HuggingFace (pour pyannote)

La diarisation n√©cessite un token HuggingFace :

1. Cr√©ez un compte sur [huggingface.co](https://huggingface.co)
2. Acceptez les conditions sur [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
3. Cr√©ez un token dans vos param√®tres
4. Configurez la variable d'environnement :

```bash
# Windows
set HF_TOKEN=votre_token_ici

# macOS/Linux
export HF_TOKEN=votre_token_ici
```

---

## üìñ Utilisation

### 1. D√©marrer LM Studio

1. T√©l√©chargez et installez [LM Studio](https://lmstudio.ai/)
2. Chargez un mod√®le (recommand√©s : Mistral-7B, Qwen2.5-7B, Llama-3.1-8B)
3. Configurez le serveur :
   - **Context Length** : 8192-32768 tokens (important !)
   - **GPU Offload** : Maximum possible
4. D√©marrez le serveur local (port 1234 par d√©faut)

### 2. Lancer Synevola

```bash
streamlit run app.py
```

L'application s'ouvre automatiquement dans votre navigateur √† `http://localhost:8501`

### 3. Workflow typique

1. **V√©rifiez les indicateurs** : CUDA ‚úÖ et LM Studio ‚úÖ dans la sidebar
2. **Importez un audio** ou **enregistrez en direct**
3. **Configurez** les param√®tres (mod√®le STT, diarisation, prompts)
4. **Cliquez** sur "üöÄ Transcrire + R√©sumer"
5. **Exportez** le r√©sultat en TXT ou DOCX

---

## ‚öôÔ∏è Configuration

### Param√®tres STT (Speech-to-Text)

| Param√®tre | Description | Valeurs |
|-----------|-------------|---------|
| Mod√®le STT | Taille du mod√®le Whisper | tiny, base, small, medium, large |
| Diarisation | Identification des locuteurs | On/Off |
| Normalisation | Conversion mono + normalisation | On/Off |

### Param√®tres LLM

| Param√®tre | Description | Valeur par d√©faut |
|-----------|-------------|-------------------|
| Temp√©rature | Cr√©ativit√© du mod√®le | 0.2 |
| Max tokens | Longueur max de la r√©ponse | 1024 |
| Taille bloc | Tokens par chunk | 6000 |
| Chevauchement | Overlap entre chunks | 200 |

### Configuration LM Studio recommand√©e

| Mod√®le | Context Length | GPU Layers |
|--------|---------------|------------|
| Mistral-7B | 8192-16384 | Max |
| Qwen2.5-7B | 32768 | Max |
| Llama-3.1-8B | 8192-16384 | Max |

---

## üìÅ Structure du projet

```
synevola/
‚îú‚îÄ‚îÄ app.py                 # Application principale Streamlit
‚îú‚îÄ‚îÄ audio_processing.py    # Pipeline de traitement audio
‚îú‚îÄ‚îÄ requirements.txt       # D√©pendances Python
‚îú‚îÄ‚îÄ README.md             # Ce fichier
‚îú‚îÄ‚îÄ LICENSE               # Licence MIT
‚îú‚îÄ‚îÄ .gitignore           # Fichiers √† ignorer
‚îú‚îÄ‚îÄ .env.example         # Exemple de configuration
‚îî‚îÄ‚îÄ docs/
    ‚îî‚îÄ‚îÄ CONFIGURATION.md  # Guide de configuration d√©taill√©
```

---

## üîß D√©pannage

### Erreur "Channel Error" ou "prediction-error" avec LM Studio

**Cause** : Context Length insuffisant

**Solution** :
1. Dans LM Studio, augmentez le Context Length (8192 ‚Üí 16384 ou plus)
2. Activez le GPU Offload au maximum
3. Rechargez le mod√®le

### Erreur "CUDA out of memory"

**Solutions** :
1. Utilisez un mod√®le STT plus petit (small au lieu de large)
2. R√©duisez le Context Length dans LM Studio
3. Fermez les autres applications GPU

### La diarisation ne fonctionne pas

**V√©rifiez** :
1. Le token HuggingFace est configur√© (`HF_TOKEN`)
2. Vous avez accept√© les conditions sur HuggingFace
3. pyannote.audio est correctement install√©

### L'enregistrement audio ne fonctionne pas

**V√©rifiez** :
1. ffmpeg est install√© (`ffmpeg -version`)
2. Le navigateur a acc√®s au microphone
3. streamlit-audiorecorder est install√©

---

## ü§ù Contribution

Les contributions sont les bienvenues ! 

1. Forkez le projet
2. Cr√©ez une branche (`git checkout -b feature/amelioration`)
3. Committez vos changements (`git commit -m 'Ajout de fonctionnalit√©'`)
4. Pushez la branche (`git push origin feature/amelioration`)
5. Ouvrez une Pull Request

---

## üìÑ Licence

Ce projet est sous licence MIT. Voir le fichier [LICENSE](LICENSE) pour plus de d√©tails.

---

## üôè Remerciements

- [OpenAI Whisper](https://github.com/openai/whisper) - Mod√®le de transcription
- [Faster Whisper](https://github.com/guillaumekln/faster-whisper) - Impl√©mentation optimis√©e
- [Pyannote](https://github.com/pyannote/pyannote-audio) - Diarisation
- [LM Studio](https://lmstudio.ai/) - Inf√©rence LLM locale
- [Streamlit](https://streamlit.io/) - Framework UI

---

## üì¨ Contact

Pour toute question ou suggestion, ouvrez une [issue](https://github.com/votre-username/synevola/issues) sur GitHub.

---

<p align="center">
  <b>Synevola</b> - Transcription m√©dicale intelligente, 100% locale et confidentielle üîí
</p>
